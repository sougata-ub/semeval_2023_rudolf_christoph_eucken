{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "065091a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 09:17:21.575575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-20 09:17:21.730542: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-20 09:17:22.322627: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.6/lib64:/usr/local/cuda-11.6/lib64\n",
      "2023-02-20 09:17:22.322701: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.6/lib64:/usr/local/cuda-11.6/lib64\n",
      "2023-02-20 09:17:22.322706: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data import SequentialSampler, TensorDataset, RandomSampler\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.cuda.amp import autocast\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9abfa6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62020c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cats = json.load(open(\"../data/value-categories.json\"))\n",
    "tags = [\"training\", \"validation\"]\n",
    "data_dict = {}\n",
    "ratio_hard = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c09a37c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = sorted(list(val_cats.keys()))\n",
    "all_labels_reduced = sorted(list(set([i.split(\":\")[0] for i in list(val_cats.keys())])))\n",
    "id_2_class = {ix:i for ix, i in enumerate(all_labels)}\n",
    "id_2_class_reduced = {ix:i for ix, i in enumerate(all_labels_reduced)}\n",
    "\n",
    "len(all_labels), len(all_labels_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4497b362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5393"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = pickle.load(open(\"../data/data_dict_raw.pkl\", \"rb\"))\n",
    "len(data_dict[\"training\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8f1613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dict = {}\n",
    "for tag in tags:\n",
    "    if example_dict.get(tag, None) is None:\n",
    "        example_dict[tag] = []\n",
    "        \n",
    "    for k, v in data_dict[tag].items():\n",
    "        tmp = [0] * len(all_labels)\n",
    "        tmp_red = [0] * len(all_labels_reduced)\n",
    "        \n",
    "        for ix, i in enumerate(all_labels):\n",
    "            if i in v[\"labels\"]:\n",
    "                tmp[ix] = 1\n",
    "        \n",
    "        red_labels = set([i.split(\":\")[0] for i in v[\"labels\"]])\n",
    "        for ix, i in enumerate(all_labels_reduced):\n",
    "            if i in red_labels:\n",
    "                tmp_red[ix] = 1\n",
    "        example_dict[tag].append([k, v[\"sent\"], tmp, tmp_red])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf0ce3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(example_dict, open(\"../data/example_dict_standard_raw.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd026677",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09dfbc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "example_dict = pickle.load(open(\"../data/example_dict_standard_raw.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b170909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encodings(lst):\n",
    "    all_toks = tokenizer([example[1] for example in lst], padding=True)\n",
    "    all_lbl = [example[-2] for example in lst]\n",
    "    red_lbl = [example[-1] for example in lst]\n",
    "    return torch.tensor(all_toks.input_ids), torch.tensor(all_toks.attention_mask), \\\n",
    "            torch.tensor(all_lbl), torch.tensor(red_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a6dcb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5393, 166]) torch.Size([5393, 166]) torch.Size([5393, 20]) torch.Size([5393, 12])\n",
      "torch.Size([1896, 159]) torch.Size([1896, 159]) torch.Size([1896, 20]) torch.Size([1896, 12])\n"
     ]
    }
   ],
   "source": [
    "train_input_ids, train_attention_mask, train_labels, train_red_labels = get_encodings(example_dict[\"training\"])\n",
    "valid_input_ids, valid_attention_mask, valid_labels, valid_red_labels = get_encodings(example_dict[\"validation\"])\n",
    "\n",
    "print(train_input_ids.shape, train_attention_mask.shape, train_labels.shape, train_red_labels.shape)\n",
    "print(valid_input_ids.shape, valid_attention_mask.shape, valid_labels.shape, valid_red_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "326584d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self, base_model, n_classes):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.ff = nn.Linear(768, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        op = self.base_model(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "        return self.ff(op[\"pooler_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90dfe304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def train(model, optimizer, dataloader, device):\n",
    "    model.train()\n",
    "    ep_t_loss, batch_num = 0, 0\n",
    "    loss_fct = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    for ix, batch in tqdm(enumerate(dataloader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, attention_mask, labels_all, labels_red = batch\n",
    "        labels = labels_all if n_classes == 20 else labels_red\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output_dct = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        loss = loss_fct(output_dct.view(-1), labels.float().view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_num += 1\n",
    "        ep_t_loss += loss.item()\n",
    "    return ep_t_loss / batch_num\n",
    "\n",
    "def evaluate(model, dataloader, device, n_classes=20, threshold=0.5):\n",
    "    model.eval()\n",
    "    ep_t_loss, batch_num = 0, 0\n",
    "    loss_fct = nn.BCEWithLogitsLoss()\n",
    "    preds, actual = [], []\n",
    "    preds_cls, actual_cls = {i:[] for i in range(n_classes)}, {i:[] for i in range(n_classes)}\n",
    "    \n",
    "    for ix, batch in tqdm(enumerate(dataloader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, attention_mask, labels_all, labels_red = batch\n",
    "        labels = labels_all if n_classes == 20 else labels_red\n",
    "        with torch.no_grad():\n",
    "            output_dct = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        loss = loss_fct(output_dct.view(-1), labels.float().view(-1))\n",
    "        \n",
    "        batch_num += 1\n",
    "        ep_t_loss += loss.item()\n",
    "        prd = (torch.sigmoid(output_dct) >= threshold).long()\n",
    "        preds.extend(prd.view(-1).tolist())\n",
    "        actual.extend(labels.view(-1).tolist())\n",
    "        \n",
    "        for k in preds_cls.keys():\n",
    "            preds_cls[k].extend(prd[:,k].view(-1).tolist())\n",
    "            actual_cls[k].extend(labels[:,k].view(-1).tolist())\n",
    "            \n",
    "    print(\"VALIDATION STATS:\\n\", classification_report(actual, preds, zero_division=0))\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"CLASS WISE VALIDATION STATS:\\n\")\n",
    "    mappn = id_2_class if n_classes == 20 else id_2_class_reduced\n",
    "    for k in preds_cls.keys():\n",
    "        print(\"CLASS\", mappn[k], \":\\n\", classification_report(actual_cls[k], preds_cls[k], zero_division=0),\"\\n\")\n",
    "    print(\"====================================================\")\n",
    "    return ep_t_loss / batch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "660cdcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b433b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_input_ids, train_attention_mask, train_labels, train_red_labels)\n",
    "valid_data = TensorDataset(valid_input_ids, valid_attention_mask, valid_labels, valid_red_labels)\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=batch_size, sampler=RandomSampler(train_data), num_workers=2)\n",
    "valid_dl = DataLoader(valid_data, batch_size=batch_size, sampler=SequentialSampler(valid_data), num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74419c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 30\n",
    "best_valid_loss = float('inf')\n",
    "model_name = \"roberta_baseline_model_reduced_v1.pt\" # \"roberta_baseline_model_v1.pt\"\n",
    "early_stopping = 4\n",
    "n_classes = len(all_labels_reduced)# len(all_labels)\n",
    "device = torch.device(\"cuda:{}\".format(0)) if torch.cuda.is_available() else \"cpu\"\n",
    "model = BaselineModel(RobertaModel.from_pretrained(\"roberta-base\"), n_classes).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ba1252e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71016c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:24,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Evaluating ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "30it [00:02, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION STATS:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87     17108\n",
      "           1       0.63      0.42      0.50      5644\n",
      "\n",
      "    accuracy                           0.79     22752\n",
      "   macro avg       0.73      0.67      0.69     22752\n",
      "weighted avg       0.78      0.79      0.78     22752\n",
      "\n",
      "-------------------------------\n",
      "CLASS WISE VALIDATION STATS:\n",
      "\n",
      "CLASS Achievement :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.99      0.84      1321\n",
      "           1       0.88      0.12      0.21       575\n",
      "\n",
      "    accuracy                           0.73      1896\n",
      "   macro avg       0.80      0.56      0.52      1896\n",
      "weighted avg       0.77      0.73      0.65      1896\n",
      " \n",
      "\n",
      "CLASS Benevolence :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73      1091\n",
      "           1       0.00      0.00      0.00       805\n",
      "\n",
      "    accuracy                           0.58      1896\n",
      "   macro avg       0.29      0.50      0.37      1896\n",
      "weighted avg       0.33      0.58      0.42      1896\n",
      " \n",
      "\n",
      "CLASS Conformity :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85      1411\n",
      "           1       0.00      0.00      0.00       485\n",
      "\n",
      "    accuracy                           0.74      1896\n",
      "   macro avg       0.37      0.50      0.43      1896\n",
      "weighted avg       0.55      0.74      0.64      1896\n",
      " \n",
      "\n",
      "CLASS Face :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      1766\n",
      "           1       0.00      0.00      0.00       130\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.47      0.50      0.48      1896\n",
      "weighted avg       0.87      0.93      0.90      1896\n",
      " \n",
      "\n",
      "CLASS Hedonism :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1793\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      1896\n",
      "   macro avg       0.47      0.50      0.49      1896\n",
      "weighted avg       0.89      0.95      0.92      1896\n",
      " \n",
      "\n",
      "CLASS Humility :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      1769\n",
      "           1       0.00      0.00      0.00       127\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.47      0.50      0.48      1896\n",
      "weighted avg       0.87      0.93      0.90      1896\n",
      " \n",
      "\n",
      "CLASS Power :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92      1606\n",
      "           1       0.00      0.00      0.00       290\n",
      "\n",
      "    accuracy                           0.85      1896\n",
      "   macro avg       0.42      0.50      0.46      1896\n",
      "weighted avg       0.72      0.85      0.78      1896\n",
      " \n",
      "\n",
      "CLASS Security :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.30      0.43       787\n",
      "           1       0.65      0.93      0.77      1109\n",
      "\n",
      "    accuracy                           0.67      1896\n",
      "   macro avg       0.71      0.62      0.60      1896\n",
      "weighted avg       0.70      0.67      0.63      1896\n",
      " \n",
      "\n",
      "CLASS Self-direction :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.92      0.82      1286\n",
      "           1       0.64      0.31      0.42       610\n",
      "\n",
      "    accuracy                           0.72      1896\n",
      "   macro avg       0.69      0.62      0.62      1896\n",
      "weighted avg       0.71      0.72      0.69      1896\n",
      " \n",
      "\n",
      "CLASS Stimulation :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      1758\n",
      "           1       0.00      0.00      0.00       138\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.46      0.50      0.48      1896\n",
      "weighted avg       0.86      0.93      0.89      1896\n",
      " \n",
      "\n",
      "CLASS Tradition :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      1724\n",
      "           1       0.00      0.00      0.00       172\n",
      "\n",
      "    accuracy                           0.91      1896\n",
      "   macro avg       0.45      0.50      0.48      1896\n",
      "weighted avg       0.83      0.91      0.87      1896\n",
      " \n",
      "\n",
      "CLASS Universalism :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.08      0.14       796\n",
      "           1       0.59      0.98      0.74      1100\n",
      "\n",
      "    accuracy                           0.60      1896\n",
      "   macro avg       0.65      0.53      0.44      1896\n",
      "weighted avg       0.64      0.60      0.49      1896\n",
      " \n",
      "\n",
      "====================================================\n",
      "FOUND BEST MODEL!\n",
      "SAVING BEST MODEL!\n",
      "Epoch: 0 | Time: 0m 27s\n",
      "\tTrain Total Loss: 0.475 | Val Total Loss: 0.433\n",
      "Epoch: 1, Training ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:24,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Evaluating ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "30it [00:02, 10.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION STATS:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88     17108\n",
      "           1       0.67      0.53      0.59      5644\n",
      "\n",
      "    accuracy                           0.82     22752\n",
      "   macro avg       0.76      0.72      0.74     22752\n",
      "weighted avg       0.81      0.82      0.81     22752\n",
      "\n",
      "-------------------------------\n",
      "CLASS WISE VALIDATION STATS:\n",
      "\n",
      "CLASS Achievement :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.99      0.85      1321\n",
      "           1       0.88      0.25      0.39       575\n",
      "\n",
      "    accuracy                           0.76      1896\n",
      "   macro avg       0.82      0.62      0.62      1896\n",
      "weighted avg       0.79      0.76      0.71      1896\n",
      " \n",
      "\n",
      "CLASS Benevolence :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69      1091\n",
      "           1       0.58      0.63      0.61       805\n",
      "\n",
      "    accuracy                           0.65      1896\n",
      "   macro avg       0.65      0.65      0.65      1896\n",
      "weighted avg       0.66      0.65      0.65      1896\n",
      " \n",
      "\n",
      "CLASS Conformity :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85      1411\n",
      "           1       0.56      0.48      0.52       485\n",
      "\n",
      "    accuracy                           0.77      1896\n",
      "   macro avg       0.69      0.68      0.68      1896\n",
      "weighted avg       0.76      0.77      0.76      1896\n",
      " \n",
      "\n",
      "CLASS Face :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      1766\n",
      "           1       0.00      0.00      0.00       130\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.47      0.50      0.48      1896\n",
      "weighted avg       0.87      0.93      0.90      1896\n",
      " \n",
      "\n",
      "CLASS Hedonism :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1793\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      1896\n",
      "   macro avg       0.47      0.50      0.49      1896\n",
      "weighted avg       0.89      0.95      0.92      1896\n",
      " \n",
      "\n",
      "CLASS Humility :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      1769\n",
      "           1       0.00      0.00      0.00       127\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.47      0.50      0.48      1896\n",
      "weighted avg       0.87      0.93      0.90      1896\n",
      " \n",
      "\n",
      "CLASS Power :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.92      1606\n",
      "           1       0.52      0.11      0.18       290\n",
      "\n",
      "    accuracy                           0.85      1896\n",
      "   macro avg       0.69      0.55      0.55      1896\n",
      "weighted avg       0.81      0.85      0.80      1896\n",
      " \n",
      "\n",
      "CLASS Security :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.45      0.56       787\n",
      "           1       0.70      0.90      0.79      1109\n",
      "\n",
      "    accuracy                           0.71      1896\n",
      "   macro avg       0.73      0.67      0.67      1896\n",
      "weighted avg       0.72      0.71      0.69      1896\n",
      " \n",
      "\n",
      "CLASS Self-direction :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82      1286\n",
      "           1       0.63      0.52      0.57       610\n",
      "\n",
      "    accuracy                           0.75      1896\n",
      "   macro avg       0.71      0.69      0.70      1896\n",
      "weighted avg       0.74      0.75      0.74      1896\n",
      " \n",
      "\n",
      "CLASS Stimulation :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      1758\n",
      "           1       0.00      0.00      0.00       138\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.46      0.50      0.48      1896\n",
      "weighted avg       0.86      0.93      0.89      1896\n",
      " \n",
      "\n",
      "CLASS Tradition :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      1724\n",
      "           1       0.85      0.13      0.23       172\n",
      "\n",
      "    accuracy                           0.92      1896\n",
      "   macro avg       0.89      0.57      0.59      1896\n",
      "weighted avg       0.91      0.92      0.89      1896\n",
      " \n",
      "\n",
      "CLASS Universalism :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.72      0.66       796\n",
      "           1       0.77      0.66      0.71      1100\n",
      "\n",
      "    accuracy                           0.68      1896\n",
      "   macro avg       0.68      0.69      0.68      1896\n",
      "weighted avg       0.70      0.68      0.69      1896\n",
      " \n",
      "\n",
      "====================================================\n",
      "FOUND BEST MODEL!\n",
      "SAVING BEST MODEL!\n",
      "Epoch: 1 | Time: 0m 27s\n",
      "\tTrain Total Loss: 0.394 | Val Total Loss: 0.403\n",
      "Epoch: 2, Training ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:24,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Evaluating ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "30it [00:02, 10.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION STATS:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89     17108\n",
      "           1       0.69      0.56      0.62      5644\n",
      "\n",
      "    accuracy                           0.83     22752\n",
      "   macro avg       0.78      0.74      0.75     22752\n",
      "weighted avg       0.82      0.83      0.82     22752\n",
      "\n",
      "-------------------------------\n",
      "CLASS WISE VALIDATION STATS:\n",
      "\n",
      "CLASS Achievement :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86      1321\n",
      "           1       0.72      0.58      0.64       575\n",
      "\n",
      "    accuracy                           0.80      1896\n",
      "   macro avg       0.77      0.74      0.75      1896\n",
      "weighted avg       0.80      0.80      0.80      1896\n",
      " \n",
      "\n",
      "CLASS Benevolence :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.79      0.75      1091\n",
      "           1       0.66      0.56      0.61       805\n",
      "\n",
      "    accuracy                           0.69      1896\n",
      "   macro avg       0.69      0.67      0.68      1896\n",
      "weighted avg       0.69      0.69      0.69      1896\n",
      " \n",
      "\n",
      "CLASS Conformity :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87      1411\n",
      "           1       0.65      0.35      0.45       485\n",
      "\n",
      "    accuracy                           0.78      1896\n",
      "   macro avg       0.73      0.64      0.66      1896\n",
      "weighted avg       0.77      0.78      0.76      1896\n",
      " \n",
      "\n",
      "CLASS Face :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      1766\n",
      "           1       0.00      0.00      0.00       130\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.47      0.50      0.48      1896\n",
      "weighted avg       0.87      0.93      0.90      1896\n",
      " \n",
      "\n",
      "CLASS Hedonism :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1793\n",
      "           1       1.00      0.02      0.04       103\n",
      "\n",
      "    accuracy                           0.95      1896\n",
      "   macro avg       0.97      0.51      0.51      1896\n",
      "weighted avg       0.95      0.95      0.92      1896\n",
      " \n",
      "\n",
      "CLASS Humility :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      1769\n",
      "           1       0.33      0.01      0.02       127\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.63      0.50      0.49      1896\n",
      "weighted avg       0.89      0.93      0.90      1896\n",
      " \n",
      "\n",
      "CLASS Power :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      1606\n",
      "           1       0.49      0.31      0.38       290\n",
      "\n",
      "    accuracy                           0.84      1896\n",
      "   macro avg       0.69      0.63      0.65      1896\n",
      "weighted avg       0.82      0.84      0.83      1896\n",
      " \n",
      "\n",
      "CLASS Security :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.47      0.58       787\n",
      "           1       0.71      0.91      0.79      1109\n",
      "\n",
      "    accuracy                           0.73      1896\n",
      "   macro avg       0.75      0.69      0.69      1896\n",
      "weighted avg       0.74      0.73      0.71      1896\n",
      " \n",
      "\n",
      "CLASS Self-direction :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.83      1286\n",
      "           1       0.66      0.45      0.53       610\n",
      "\n",
      "    accuracy                           0.75      1896\n",
      "   macro avg       0.72      0.67      0.68      1896\n",
      "weighted avg       0.74      0.75      0.73      1896\n",
      " \n",
      "\n",
      "CLASS Stimulation :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      1758\n",
      "           1       0.00      0.00      0.00       138\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.46      0.50      0.48      1896\n",
      "weighted avg       0.86      0.93      0.89      1896\n",
      " \n",
      "\n",
      "CLASS Tradition :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      1724\n",
      "           1       0.80      0.22      0.34       172\n",
      "\n",
      "    accuracy                           0.92      1896\n",
      "   macro avg       0.87      0.60      0.65      1896\n",
      "weighted avg       0.92      0.92      0.90      1896\n",
      " \n",
      "\n",
      "CLASS Universalism :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.62       796\n",
      "           1       0.73      0.73      0.73      1100\n",
      "\n",
      "    accuracy                           0.69      1896\n",
      "   macro avg       0.68      0.68      0.68      1896\n",
      "weighted avg       0.69      0.69      0.69      1896\n",
      " \n",
      "\n",
      "====================================================\n",
      "FOUND BEST MODEL!\n",
      "SAVING BEST MODEL!\n",
      "Epoch: 2 | Time: 0m 27s\n",
      "\tTrain Total Loss: 0.353 | Val Total Loss: 0.386\n",
      "Epoch: 3, Training ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:24,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Evaluating ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "30it [00:02, 10.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION STATS:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89     17108\n",
      "           1       0.70      0.57      0.63      5644\n",
      "\n",
      "    accuracy                           0.83     22752\n",
      "   macro avg       0.78      0.74      0.76     22752\n",
      "weighted avg       0.82      0.83      0.83     22752\n",
      "\n",
      "-------------------------------\n",
      "CLASS WISE VALIDATION STATS:\n",
      "\n",
      "CLASS Achievement :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      1321\n",
      "           1       0.77      0.53      0.63       575\n",
      "\n",
      "    accuracy                           0.81      1896\n",
      "   macro avg       0.80      0.73      0.75      1896\n",
      "weighted avg       0.81      0.81      0.80      1896\n",
      " \n",
      "\n",
      "CLASS Benevolence :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74      1091\n",
      "           1       0.65      0.59      0.62       805\n",
      "\n",
      "    accuracy                           0.69      1896\n",
      "   macro avg       0.68      0.68      0.68      1896\n",
      "weighted avg       0.69      0.69      0.69      1896\n",
      " \n",
      "\n",
      "CLASS Conformity :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      1411\n",
      "           1       0.60      0.48      0.53       485\n",
      "\n",
      "    accuracy                           0.79      1896\n",
      "   macro avg       0.72      0.69      0.70      1896\n",
      "weighted avg       0.77      0.79      0.78      1896\n",
      " \n",
      "\n",
      "CLASS Face :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      1766\n",
      "           1       0.00      0.00      0.00       130\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.47      0.50      0.48      1896\n",
      "weighted avg       0.87      0.93      0.90      1896\n",
      " \n",
      "\n",
      "CLASS Hedonism :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1793\n",
      "           1       0.87      0.13      0.22       103\n",
      "\n",
      "    accuracy                           0.95      1896\n",
      "   macro avg       0.91      0.56      0.60      1896\n",
      "weighted avg       0.95      0.95      0.93      1896\n",
      " \n",
      "\n",
      "CLASS Humility :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      1769\n",
      "           1       0.33      0.06      0.11       127\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.63      0.53      0.53      1896\n",
      "weighted avg       0.90      0.93      0.91      1896\n",
      " \n",
      "\n",
      "CLASS Power :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92      1606\n",
      "           1       0.57      0.16      0.25       290\n",
      "\n",
      "    accuracy                           0.85      1896\n",
      "   macro avg       0.72      0.57      0.59      1896\n",
      "weighted avg       0.82      0.85      0.82      1896\n",
      " \n",
      "\n",
      "CLASS Security :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.54      0.63       787\n",
      "           1       0.73      0.88      0.80      1109\n",
      "\n",
      "    accuracy                           0.74      1896\n",
      "   macro avg       0.75      0.71      0.71      1896\n",
      "weighted avg       0.74      0.74      0.73      1896\n",
      " \n",
      "\n",
      "CLASS Self-direction :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.85      1286\n",
      "           1       0.77      0.42      0.55       610\n",
      "\n",
      "    accuracy                           0.77      1896\n",
      "   macro avg       0.77      0.68      0.70      1896\n",
      "weighted avg       0.77      0.77      0.75      1896\n",
      " \n",
      "\n",
      "CLASS Stimulation :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      1758\n",
      "           1       0.50      0.05      0.09       138\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.72      0.52      0.53      1896\n",
      "weighted avg       0.90      0.93      0.90      1896\n",
      " \n",
      "\n",
      "CLASS Tradition :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      1724\n",
      "           1       0.68      0.24      0.36       172\n",
      "\n",
      "    accuracy                           0.92      1896\n",
      "   macro avg       0.80      0.62      0.66      1896\n",
      "weighted avg       0.91      0.92      0.90      1896\n",
      " \n",
      "\n",
      "CLASS Universalism :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.58      0.60       796\n",
      "           1       0.71      0.75      0.73      1100\n",
      "\n",
      "    accuracy                           0.68      1896\n",
      "   macro avg       0.67      0.67      0.67      1896\n",
      "weighted avg       0.68      0.68      0.68      1896\n",
      " \n",
      "\n",
      "====================================================\n",
      "FOUND BEST MODEL!\n",
      "SAVING BEST MODEL!\n",
      "Epoch: 3 | Time: 0m 27s\n",
      "\tTrain Total Loss: 0.321 | Val Total Loss: 0.385\n",
      "Epoch: 4, Training ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:24,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Evaluating ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "30it [00:02, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION STATS:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89     17108\n",
      "           1       0.70      0.56      0.62      5644\n",
      "\n",
      "    accuracy                           0.83     22752\n",
      "   macro avg       0.78      0.74      0.76     22752\n",
      "weighted avg       0.82      0.83      0.82     22752\n",
      "\n",
      "-------------------------------\n",
      "CLASS WISE VALIDATION STATS:\n",
      "\n",
      "CLASS Achievement :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87      1321\n",
      "           1       0.75      0.56      0.64       575\n",
      "\n",
      "    accuracy                           0.81      1896\n",
      "   macro avg       0.79      0.74      0.76      1896\n",
      "weighted avg       0.80      0.81      0.80      1896\n",
      " \n",
      "\n",
      "CLASS Benevolence :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.81      0.75      1091\n",
      "           1       0.68      0.54      0.60       805\n",
      "\n",
      "    accuracy                           0.69      1896\n",
      "   macro avg       0.69      0.67      0.68      1896\n",
      "weighted avg       0.69      0.69      0.69      1896\n",
      " \n",
      "\n",
      "CLASS Conformity :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87      1411\n",
      "           1       0.63      0.41      0.50       485\n",
      "\n",
      "    accuracy                           0.79      1896\n",
      "   macro avg       0.73      0.67      0.68      1896\n",
      "weighted avg       0.77      0.79      0.77      1896\n",
      " \n",
      "\n",
      "CLASS Face :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      1766\n",
      "           1       0.00      0.00      0.00       130\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.47      0.50      0.48      1896\n",
      "weighted avg       0.87      0.93      0.90      1896\n",
      " \n",
      "\n",
      "CLASS Hedonism :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1793\n",
      "           1       0.70      0.14      0.23       103\n",
      "\n",
      "    accuracy                           0.95      1896\n",
      "   macro avg       0.83      0.57      0.60      1896\n",
      "weighted avg       0.94      0.95      0.93      1896\n",
      " \n",
      "\n",
      "CLASS Humility :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      1769\n",
      "           1       0.43      0.07      0.12       127\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.68      0.53      0.54      1896\n",
      "weighted avg       0.90      0.93      0.91      1896\n",
      " \n",
      "\n",
      "CLASS Power :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1606\n",
      "           1       0.57      0.27      0.36       290\n",
      "\n",
      "    accuracy                           0.86      1896\n",
      "   macro avg       0.72      0.61      0.64      1896\n",
      "weighted avg       0.83      0.86      0.83      1896\n",
      " \n",
      "\n",
      "CLASS Security :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.57      0.63       787\n",
      "           1       0.73      0.83      0.78      1109\n",
      "\n",
      "    accuracy                           0.73      1896\n",
      "   macro avg       0.72      0.70      0.71      1896\n",
      "weighted avg       0.72      0.73      0.72      1896\n",
      " \n",
      "\n",
      "CLASS Self-direction :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82      1286\n",
      "           1       0.64      0.53      0.58       610\n",
      "\n",
      "    accuracy                           0.75      1896\n",
      "   macro avg       0.72      0.69      0.70      1896\n",
      "weighted avg       0.74      0.75      0.75      1896\n",
      " \n",
      "\n",
      "CLASS Stimulation :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      1758\n",
      "           1       0.56      0.07      0.13       138\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.74      0.53      0.55      1896\n",
      "weighted avg       0.90      0.93      0.90      1896\n",
      " \n",
      "\n",
      "CLASS Tradition :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      1724\n",
      "           1       0.68      0.24      0.35       172\n",
      "\n",
      "    accuracy                           0.92      1896\n",
      "   macro avg       0.81      0.61      0.66      1896\n",
      "weighted avg       0.91      0.92      0.90      1896\n",
      " \n",
      "\n",
      "CLASS Universalism :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.61       796\n",
      "           1       0.72      0.74      0.73      1100\n",
      "\n",
      "    accuracy                           0.68      1896\n",
      "   macro avg       0.67      0.67      0.67      1896\n",
      "weighted avg       0.68      0.68      0.68      1896\n",
      " \n",
      "\n",
      "====================================================\n",
      "Epoch: 4 | Time: 0m 27s\n",
      "\tTrain Total Loss: 0.293 | Val Total Loss: 0.386\n",
      "Epoch: 5, Training ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:24,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Evaluating ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "30it [00:02, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION STATS:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89     17108\n",
      "           1       0.68      0.58      0.63      5644\n",
      "\n",
      "    accuracy                           0.83     22752\n",
      "   macro avg       0.77      0.75      0.76     22752\n",
      "weighted avg       0.82      0.83      0.82     22752\n",
      "\n",
      "-------------------------------\n",
      "CLASS WISE VALIDATION STATS:\n",
      "\n",
      "CLASS Achievement :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86      1321\n",
      "           1       0.70      0.60      0.65       575\n",
      "\n",
      "    accuracy                           0.80      1896\n",
      "   macro avg       0.77      0.75      0.76      1896\n",
      "weighted avg       0.80      0.80      0.80      1896\n",
      " \n",
      "\n",
      "CLASS Benevolence :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73      1091\n",
      "           1       0.63      0.59      0.61       805\n",
      "\n",
      "    accuracy                           0.68      1896\n",
      "   macro avg       0.67      0.67      0.67      1896\n",
      "weighted avg       0.68      0.68      0.68      1896\n",
      " \n",
      "\n",
      "CLASS Conformity :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86      1411\n",
      "           1       0.61      0.47      0.53       485\n",
      "\n",
      "    accuracy                           0.79      1896\n",
      "   macro avg       0.72      0.68      0.70      1896\n",
      "weighted avg       0.77      0.79      0.78      1896\n",
      " \n",
      "\n",
      "CLASS Face :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      1766\n",
      "           1       0.44      0.03      0.06       130\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.69      0.51      0.51      1896\n",
      "weighted avg       0.90      0.93      0.90      1896\n",
      " \n",
      "\n",
      "CLASS Hedonism :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1793\n",
      "           1       0.76      0.16      0.26       103\n",
      "\n",
      "    accuracy                           0.95      1896\n",
      "   macro avg       0.86      0.58      0.62      1896\n",
      "weighted avg       0.94      0.95      0.94      1896\n",
      " \n",
      "\n",
      "CLASS Humility :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      1769\n",
      "           1       0.23      0.09      0.13       127\n",
      "\n",
      "    accuracy                           0.92      1896\n",
      "   macro avg       0.58      0.54      0.55      1896\n",
      "weighted avg       0.89      0.92      0.90      1896\n",
      " \n",
      "\n",
      "CLASS Power :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      1606\n",
      "           1       0.51      0.35      0.42       290\n",
      "\n",
      "    accuracy                           0.85      1896\n",
      "   macro avg       0.70      0.65      0.66      1896\n",
      "weighted avg       0.83      0.85      0.84      1896\n",
      " \n",
      "\n",
      "CLASS Security :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.65       787\n",
      "           1       0.75      0.80      0.77      1109\n",
      "\n",
      "    accuracy                           0.73      1896\n",
      "   macro avg       0.72      0.71      0.71      1896\n",
      "weighted avg       0.72      0.73      0.72      1896\n",
      " \n",
      "\n",
      "CLASS Self-direction :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84      1286\n",
      "           1       0.68      0.52      0.59       610\n",
      "\n",
      "    accuracy                           0.77      1896\n",
      "   macro avg       0.74      0.70      0.72      1896\n",
      "weighted avg       0.76      0.77      0.76      1896\n",
      " \n",
      "\n",
      "CLASS Stimulation :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      1758\n",
      "           1       0.69      0.08      0.14       138\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.81      0.54      0.55      1896\n",
      "weighted avg       0.91      0.93      0.90      1896\n",
      " \n",
      "\n",
      "CLASS Tradition :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      1724\n",
      "           1       0.63      0.24      0.35       172\n",
      "\n",
      "    accuracy                           0.92      1896\n",
      "   macro avg       0.78      0.61      0.65      1896\n",
      "weighted avg       0.90      0.92      0.90      1896\n",
      " \n",
      "\n",
      "CLASS Universalism :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.55      0.59       796\n",
      "           1       0.70      0.78      0.74      1100\n",
      "\n",
      "    accuracy                           0.68      1896\n",
      "   macro avg       0.67      0.66      0.66      1896\n",
      "weighted avg       0.68      0.68      0.68      1896\n",
      " \n",
      "\n",
      "====================================================\n",
      "Epoch: 5 | Time: 0m 28s\n",
      "\tTrain Total Loss: 0.267 | Val Total Loss: 0.397\n",
      "Epoch: 6, Training ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:24,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Evaluating ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "30it [00:02, 10.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION STATS:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89     17108\n",
      "           1       0.67      0.60      0.63      5644\n",
      "\n",
      "    accuracy                           0.83     22752\n",
      "   macro avg       0.77      0.75      0.76     22752\n",
      "weighted avg       0.82      0.83      0.82     22752\n",
      "\n",
      "-------------------------------\n",
      "CLASS WISE VALIDATION STATS:\n",
      "\n",
      "CLASS Achievement :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87      1321\n",
      "           1       0.74      0.56      0.64       575\n",
      "\n",
      "    accuracy                           0.81      1896\n",
      "   macro avg       0.78      0.74      0.75      1896\n",
      "weighted avg       0.80      0.81      0.80      1896\n",
      " \n",
      "\n",
      "CLASS Benevolence :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.78      0.74      1091\n",
      "           1       0.66      0.57      0.61       805\n",
      "\n",
      "    accuracy                           0.69      1896\n",
      "   macro avg       0.68      0.67      0.68      1896\n",
      "weighted avg       0.69      0.69      0.69      1896\n",
      " \n",
      "\n",
      "CLASS Conformity :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      1411\n",
      "           1       0.54      0.59      0.56       485\n",
      "\n",
      "    accuracy                           0.77      1896\n",
      "   macro avg       0.70      0.71      0.70      1896\n",
      "weighted avg       0.77      0.77      0.77      1896\n",
      " \n",
      "\n",
      "CLASS Face :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      1766\n",
      "           1       0.41      0.07      0.12       130\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.67      0.53      0.54      1896\n",
      "weighted avg       0.90      0.93      0.91      1896\n",
      " \n",
      "\n",
      "CLASS Hedonism :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1793\n",
      "           1       0.63      0.26      0.37       103\n",
      "\n",
      "    accuracy                           0.95      1896\n",
      "   macro avg       0.79      0.63      0.67      1896\n",
      "weighted avg       0.94      0.95      0.94      1896\n",
      " \n",
      "\n",
      "CLASS Humility :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1769\n",
      "           1       0.18      0.13      0.15       127\n",
      "\n",
      "    accuracy                           0.90      1896\n",
      "   macro avg       0.56      0.54      0.55      1896\n",
      "weighted avg       0.89      0.90      0.89      1896\n",
      " \n",
      "\n",
      "CLASS Power :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      1606\n",
      "           1       0.50      0.31      0.38       290\n",
      "\n",
      "    accuracy                           0.85      1896\n",
      "   macro avg       0.69      0.63      0.65      1896\n",
      "weighted avg       0.83      0.85      0.83      1896\n",
      " \n",
      "\n",
      "CLASS Security :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.52      0.61       787\n",
      "           1       0.72      0.87      0.78      1109\n",
      "\n",
      "    accuracy                           0.72      1896\n",
      "   macro avg       0.73      0.69      0.70      1896\n",
      "weighted avg       0.72      0.72      0.71      1896\n",
      " \n",
      "\n",
      "CLASS Self-direction :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83      1286\n",
      "           1       0.66      0.54      0.59       610\n",
      "\n",
      "    accuracy                           0.76      1896\n",
      "   macro avg       0.73      0.70      0.71      1896\n",
      "weighted avg       0.75      0.76      0.75      1896\n",
      " \n",
      "\n",
      "CLASS Stimulation :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      1758\n",
      "           1       0.51      0.15      0.23       138\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.72      0.57      0.60      1896\n",
      "weighted avg       0.91      0.93      0.91      1896\n",
      " \n",
      "\n",
      "CLASS Tradition :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      1724\n",
      "           1       0.67      0.27      0.39       172\n",
      "\n",
      "    accuracy                           0.92      1896\n",
      "   macro avg       0.80      0.63      0.67      1896\n",
      "weighted avg       0.91      0.92      0.91      1896\n",
      " \n",
      "\n",
      "CLASS Universalism :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.60      0.62       796\n",
      "           1       0.73      0.76      0.74      1100\n",
      "\n",
      "    accuracy                           0.69      1896\n",
      "   macro avg       0.68      0.68      0.68      1896\n",
      "weighted avg       0.69      0.69      0.69      1896\n",
      " \n",
      "\n",
      "====================================================\n",
      "Epoch: 6 | Time: 0m 28s\n",
      "\tTrain Total Loss: 0.241 | Val Total Loss: 0.414\n",
      "Epoch: 7, Training ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:24,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Evaluating ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "30it [00:02, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION STATS:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88     17108\n",
      "           1       0.64      0.60      0.62      5644\n",
      "\n",
      "    accuracy                           0.82     22752\n",
      "   macro avg       0.76      0.75      0.75     22752\n",
      "weighted avg       0.81      0.82      0.82     22752\n",
      "\n",
      "-------------------------------\n",
      "CLASS WISE VALIDATION STATS:\n",
      "\n",
      "CLASS Achievement :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86      1321\n",
      "           1       0.68      0.61      0.65       575\n",
      "\n",
      "    accuracy                           0.80      1896\n",
      "   macro avg       0.76      0.74      0.75      1896\n",
      "weighted avg       0.79      0.80      0.79      1896\n",
      " \n",
      "\n",
      "CLASS Benevolence :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.58      0.66      1091\n",
      "           1       0.57      0.76      0.65       805\n",
      "\n",
      "    accuracy                           0.66      1896\n",
      "   macro avg       0.67      0.67      0.66      1896\n",
      "weighted avg       0.68      0.66      0.66      1896\n",
      " \n",
      "\n",
      "CLASS Conformity :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84      1411\n",
      "           1       0.53      0.55      0.54       485\n",
      "\n",
      "    accuracy                           0.76      1896\n",
      "   macro avg       0.69      0.69      0.69      1896\n",
      "weighted avg       0.76      0.76      0.76      1896\n",
      " \n",
      "\n",
      "CLASS Face :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      1766\n",
      "           1       0.32      0.06      0.10       130\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.63      0.53      0.53      1896\n",
      "weighted avg       0.89      0.93      0.90      1896\n",
      " \n",
      "\n",
      "CLASS Hedonism :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      1793\n",
      "           1       0.69      0.24      0.36       103\n",
      "\n",
      "    accuracy                           0.95      1896\n",
      "   macro avg       0.83      0.62      0.67      1896\n",
      "weighted avg       0.94      0.95      0.94      1896\n",
      " \n",
      "\n",
      "CLASS Humility :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1769\n",
      "           1       0.19      0.13      0.15       127\n",
      "\n",
      "    accuracy                           0.90      1896\n",
      "   macro avg       0.56      0.54      0.55      1896\n",
      "weighted avg       0.89      0.90      0.90      1896\n",
      " \n",
      "\n",
      "CLASS Power :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      1606\n",
      "           1       0.51      0.34      0.40       290\n",
      "\n",
      "    accuracy                           0.85      1896\n",
      "   macro avg       0.70      0.64      0.66      1896\n",
      "weighted avg       0.83      0.85      0.84      1896\n",
      " \n",
      "\n",
      "CLASS Security :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68       787\n",
      "           1       0.79      0.68      0.73      1109\n",
      "\n",
      "    accuracy                           0.71      1896\n",
      "   macro avg       0.71      0.71      0.70      1896\n",
      "weighted avg       0.72      0.71      0.71      1896\n",
      " \n",
      "\n",
      "CLASS Self-direction :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1286\n",
      "           1       0.60      0.59      0.60       610\n",
      "\n",
      "    accuracy                           0.74      1896\n",
      "   macro avg       0.71      0.70      0.71      1896\n",
      "weighted avg       0.74      0.74      0.74      1896\n",
      " \n",
      "\n",
      "CLASS Stimulation :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      1758\n",
      "           1       0.52      0.11      0.18       138\n",
      "\n",
      "    accuracy                           0.93      1896\n",
      "   macro avg       0.73      0.55      0.57      1896\n",
      "weighted avg       0.90      0.93      0.91      1896\n",
      " \n",
      "\n",
      "CLASS Tradition :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      1724\n",
      "           1       0.68      0.28      0.40       172\n",
      "\n",
      "    accuracy                           0.92      1896\n",
      "   macro avg       0.80      0.63      0.68      1896\n",
      "weighted avg       0.91      0.92      0.91      1896\n",
      " \n",
      "\n",
      "CLASS Universalism :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.56      0.59       796\n",
      "           1       0.71      0.76      0.73      1100\n",
      "\n",
      "    accuracy                           0.68      1896\n",
      "   macro avg       0.67      0.66      0.66      1896\n",
      "weighted avg       0.67      0.68      0.68      1896\n",
      " \n",
      "\n",
      "====================================================\n",
      "Epoch: 7 | Time: 0m 28s\n",
      "\tTrain Total Loss: 0.215 | Val Total Loss: 0.434\n",
      "Early stopping training as the Validation loss did NOT improve for last 4 iterations.\n"
     ]
    }
   ],
   "source": [
    "t_loss, v_loss, early_stopping_marker = [], [], []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(\"Epoch: {}, Training ...\\n\".format(epoch))\n",
    "    start_time = time.time()\n",
    "\n",
    "    tr_l = train(model, optimizer, train_dl, device)\n",
    "    t_loss.append(tr_l)\n",
    "    \n",
    "    print(\"Epoch: {}, Evaluating ...\\n\".format(epoch))\n",
    "    vl_l = evaluate(model, valid_dl, device, n_classes=n_classes)\n",
    "    v_loss.append(vl_l)\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if vl_l <= best_valid_loss:\n",
    "        best_valid_loss = vl_l\n",
    "        print(\"FOUND BEST MODEL!\")\n",
    "        print(\"SAVING BEST MODEL!\")\n",
    "        torch.save(model.state_dict(), model_name)\n",
    "        early_stopping_marker.append(False)\n",
    "    else:\n",
    "        early_stopping_marker.append(True)\n",
    "    print(f'Epoch: {epoch} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Total Loss: {tr_l:.3f} | Val Total Loss: {vl_l:.3f}')\n",
    "    if all(early_stopping_marker[-early_stopping:]) and len(early_stopping_marker) >= early_stopping:\n",
    "        print(\"Early stopping training as the Validation loss did NOT improve for last \" + \\\n",
    "              str(early_stopping) + \" iterations.\")\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc4eaac",
   "metadata": {},
   "source": [
    "### Predict on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b04400e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:{}\".format(0)) if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "roberta = RobertaModel.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a7a0a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(reduced=False):\n",
    "    if reduced:\n",
    "        model_name = \"roberta_baseline_model_reduced_v1.pt\" #\"roberta_baseline_model_v1.pt\"\n",
    "        n_classes = len(all_labels_reduced)\n",
    "    else:\n",
    "        model_name = \"roberta_baseline_model_v1.pt\"\n",
    "        n_classes = len(all_labels)\n",
    "\n",
    "    model = BaselineModel(roberta, n_classes).to(device)\n",
    "    state_dict = torch.load(model_name)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    print(\"Model loaded!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e791bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n",
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "reduced_model, full_model = get_model(reduced=True), get_model(reduced=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6657f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60bae340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1576, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_df = pd.read_csv(\"../data/arguments-\"+split+\".tsv\", sep=\"\\t\")\n",
    "arg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d14a5d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1576it [00:00, 25186.79it/s]\n",
      "25it [00:05,  4.91it/s]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "batch_size = 64\n",
    "threshold = 0.5\n",
    "\n",
    "all_res = {}\n",
    "sents = []\n",
    "for ix, row in tqdm(arg_df.iterrows()):\n",
    "    stance = \" against. \" if row[\"Stance\"] == \"against\" else \" in favor of. \"\n",
    "    sents.append(row[\"Premise\"] + stance + row[\"Conclusion\"])\n",
    "    \n",
    "all_toks = tokenizer(sents, padding=True)\n",
    "input_ids, attention_mask = torch.tensor(all_toks.input_ids), torch.tensor(all_toks.attention_mask)\n",
    "test_data = TensorDataset(input_ids, attention_mask)\n",
    "test_dl = DataLoader(test_data, batch_size=batch_size, sampler=SequentialSampler(test_data), num_workers=2)\n",
    "\n",
    "preds_full, preds_red = [], []\n",
    "for ix, batch in tqdm(enumerate(test_dl)):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    input_ids, attention_mask = batch\n",
    "    with torch.no_grad():\n",
    "        op_full = full_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        op_red = reduced_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds_full.extend((torch.sigmoid(op_full) >= threshold).long().tolist())\n",
    "        preds_red.extend((torch.sigmoid(op_red) >= threshold).long().tolist())\n",
    "\n",
    "for e_id, pred in enumerate(preds_full):\n",
    "    tmp = {\"full\": [id_2_class[ix] for ix, i in enumerate(pred) if i == 1],\n",
    "           \"reduced\": [id_2_class_reduced[ix] for ix, i in enumerate(preds_red[e_id]) if i == 1]}\n",
    "    all_res[arg_df.iloc[e_id][\"Argument ID\"]] = tmp\n",
    "\n",
    "pickle.dump(all_res, open(\"../data/\"+split+\"_prediction_logit_dict_baseline_v1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdf1722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_res[\"A07099\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537d31a6",
   "metadata": {},
   "source": [
    " ### Submission Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b25e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"test\"\n",
    "thresh = \"thresh_8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096de029",
   "metadata": {},
   "source": [
    "best combos:\n",
    "    1. thresh_8\n",
    "    2. thresh_8 + base full\n",
    "    3. thresh_8 + base reduced filter\n",
    "    4. thresh_8 + base full + reduced filter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76e598c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_lbl_dct_fine = pickle.load(open(\"../data/\"+split+\"_prediction_label_dict_v1.pkl\", \"rb\"))\n",
    "res_lbl_dct_base_all = pickle.load(open(\"../data/\"+split+\"_prediction_logit_dict_baseline_v1.pkl\", \"rb\"))\n",
    "col_names = list(pd.read_csv(\"../data/labels-validation.tsv\", sep=\"\\t\").columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f49d07cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_format(valu=None):\n",
    "    if valu == 1:\n",
    "        return {k:v[\"thresh_8\"] for k,v in res_lbl_dct_fine.items()}\n",
    "    \n",
    "    elif valu == 2:\n",
    "        return {k: list(set(v[\"thresh_8\"] + res_lbl_dct_base_all[k][\"full\"])) for k, v in res_lbl_dct_fine.items()} \n",
    "    \n",
    "    elif valu == 3:\n",
    "        return {k: [i for i in v[\"thresh_8\"] if i.split(\":\")[0] in res_lbl_dct_base_all[k][\"reduced\"]] \n",
    "                for k, v in res_lbl_dct_fine.items()}\n",
    "        \n",
    "    elif valu == 4:\n",
    "        res_lbl_dct_base = {}\n",
    "        for k,v in res_lbl_dct_base_all.items():\n",
    "            res_lbl_dct_base[k] = [i for i in v[\"full\"] if i.split(\":\")[0] in v[\"reduced\"]]\n",
    "        return {k: list(set(v[\"thresh_8\"] + res_lbl_dct_base[k])) for k, v in res_lbl_dct_fine.items()}  \n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "556a5a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Setting 1\n",
      "1896\n",
      "(1896, 21)\n",
      "Saved to Location:  ./validation_setting_1.tsv \n",
      "\n",
      "For Setting 2\n",
      "1896\n",
      "(1896, 21)\n",
      "Saved to Location:  ./validation_setting_2.tsv \n",
      "\n",
      "For Setting 3\n",
      "1896\n",
      "(1896, 21)\n",
      "Saved to Location:  ./validation_setting_3.tsv \n",
      "\n",
      "For Setting 4\n",
      "1896\n",
      "(1896, 21)\n",
      "Saved to Location:  ./validation_setting_4.tsv \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    print(\"For Setting\",i)\n",
    "    res_lbl_dct = get_format(i)\n",
    "    print(len(res_lbl_dct))\n",
    "    \n",
    "    op_lst = []\n",
    "    for arg_id, v in res_lbl_dct.items():\n",
    "        t_lbl = [1 if i in v else 0 for ix, i in enumerate(col_names[1:])]\n",
    "        op_lst.append([arg_id] + t_lbl)\n",
    "    op_df = pd.DataFrame(op_lst, columns=col_names)\n",
    "    print(op_df.shape)\n",
    "    op_name = \"./\"+split+\"_setting_\"+str(i)+\".tsv\"\n",
    "    op_df.to_csv(op_name, sep=\"\\t\", index=False)\n",
    "    print(\"Saved to Location: \",op_name,\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
